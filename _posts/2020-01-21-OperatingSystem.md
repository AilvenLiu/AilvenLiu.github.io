---
layout:     post
title:      操作系统常见问题合集          
subtitle:   操作系统               
date:       2022-04-21
author:     OUC_LiuX
header-img: img/wallpic02.jpg
catalog: true
tags:          
    - CS basis
---      

## Backtrace 是怎么产生的           
backtrace 的实现依赖于栈指针（fp寄存器），FP寄存器保存的是上一个函数的栈底，然后一层层出栈即可得到函数调用过程。在gcc编译过程中任何非零的优化等级（-On参数）或加入了栈指针优化参数 `-fomit-frame-pointer` 后多将不能正确得到程序栈信息。             


## CAS 是什么东西         
CAS(Compare And Swap) 是一种无锁实现原子性数据更新的操作。具体而言，CAS 机制中有三个核心参数：V，A，B。其中，V 是数据对应的内存地址，A 是 V 地址对应的数据旧的期望值，B 是数据新的期望值。当线程要通过 CAS 机制修改主内存 V 中的值，则先将旧的数据期望值 A 读出到工作内存，在将新的期望值 B 写入到主内存前，先比较当前内存 V 中的数据是否等于 A，如果是，证明该内存处存储的数据没有被修改过，将 B 写入，并返回 true；否则，不作任何操作并返回 false。            

CAS 的全过程在操作系统中只由一条不可分割的 `cmpxchgl` 硬件汇编指令实现，指令执行不可中断，是直接对 CPU 进行操作，从而在硬件层面保证了其原子性。但是，单单这一条指令在多核状态下依旧不能保证原子性。多和状态下需要在该指令前添加一条 `lock` 指令，该指令会锁定总线（阻止CPU通过总线读写内存，代价过高，当数据位于 L1～L3 Cache，且数据长度不超过 cache line ，则只会锁住缓存行）或 CPU 的缓存行从而保证操作的原子性。         

进一步地，如果发现数据已经被其他线程更改，就开始轮询，不断重试，直到成功修改。就是 **乐观锁** 的一种实现。         

#### CAS 的优缺点：         
优点：     
1. 保证变量操作的原子性。          
2. 并发量不是很高的情况下，使用 CAS 机制比使用锁机制效率更高。          
3. 在线程对共享资源占用时间较短的情况下，使用 CAS 机制效率更高。           

缺点：       
1. ABA 问题：假设两个线程，线程1 和线程2， 按照顺序有如下操作：         
   1） 线程1 读取内存中的数据为 A；          
   2） 线程2 修改内存中的数据为 B；        
   3） 线程2 修改内存中的数据为 A;       
   4） 线程1 堆内存中的数据执行 CAS 操作。           
   显然，内存中的数据被线程2 修改过，但是线程1 在修改前比较读出时和当前的值相等， CAS 是可以成功的。          
   该问题带来的典型隐患如 **栈顶问题** ，一个栈的栈顶经过两次(或多次)变化又恢复了原值，但是栈可能已发生了变化。            

   解决 ABA 问题比较有效的方案是引入版本号，内存中的值每一次发生变化，版本号都 +1， 进行 CAS 操作时不仅比较内存中的值，也比较版本号是否相等，只有当二者都未变化时，CAS 才能成功执行。           

2. 高竞争下的开销问题。实际这属于使用 CAS 实现的乐观锁的问题，在并发冲突概率大的高竞争环境下，如果CAS一直失败，会一直重试，CPU开销较大。针对这个问题的一个思路是引入退出机制，如重试次数超过一定阈值后失败退出。当然，更重要的是避免在高竞争环境下使用乐观锁。          

3. CAS 只能保证变量操作的原子性，无法保证整个代码块的线程安全。        


#### 什么是原子性       
上文提到了原子性。原子性是指一个或者多个操作在 CPU 执行的过程中不被中断的特性，要么完整执行成功，要么退回到初始状态，，不能只执行到一半。         


## 乐观锁，悲观锁，互斥锁，自旋锁，读写锁是些什么锁           

* **乐观锁：**       
  乐观锁或悲观锁是一种编程思想，并不是真正的实现。乐观锁实际上是不加锁，是一种无锁编程方式。乐观锁认为，其他线程争抢共享变量的概率相对小，所以更新数据的时候不会对共享变量加锁，但是在正式将数据写入内存之前会检查该数据是否被其他线程修改过（值或版本号）。如果未被修改过，则写入内存完成修改，否则就重试直到成功为止。可以认为，CAS + 轮询 就是乐观锁的一种实现。**乐观锁适用于冲突概率较低的情况，适用于读操作较多的应用类型**，这样可以提高吞吐量。          
  一个典型的例子是在线文档，由于发生冲突的概率较低，所以先允许用户进行编辑，但是浏览器下载文档时会记录下服务端返回的文档版本号；当用户提交修改时，发送给服务端的请求会带上原始文档的版本号，服务器收到后将它与当前版本号进行比较。版本号一致则修改成功，否则修改失败。         

* **悲观锁：**                  
  悲观锁则认为目标资源被其他线程竞争的概率相对较大，因此操作共享资源的时候总是对资源加锁，直到操作结束后释放。加锁的资源既可以是变量，也可以是代码块。互斥所、自旋锁和读写锁等等都是悲观锁的具体实现。           

* **互斥锁：**             
  互斥锁和自旋锁是最基本的两种加锁方式，是其他较高级锁的基础。当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁的区别就在于对于加锁失败的线程的处理方式上。          
  互斥锁加锁失败后，当前线程会 **释放 CPU 资源** 给其他线程，自己进入阻塞状态，从用户态陷入到内核态。当锁被释放后，内核负责将该线程重新唤醒，由阻塞状态恢复为就绪状态，从内核态恢复到用户态。        
  互斥所存在一定的性能开销成本。具体而言，线程互斥锁加锁失败后存在从用户态（就绪）到内核态（阻塞）和从内核态返回用户态的两次转换，相应地需要保存和恢复线程相关的寄存器和栈，也就是线程的上下文切换。于是如果**被锁住的代码的执行时间较短，甚至比线程上下文切换的时间还短，就不应该使用互斥锁。**       

* **自旋锁：**             
  自旋锁则不存在线程上线文切换的问题。一般的，加锁过程分为两步：查看锁的状态，如果空闲则将锁设为当前线程持有。自旋锁通过 CAS 函数实现这一过程。CAS 将这两部操作合并为一条不可分的硬件指令，在硬件层面保证了加锁操作的原子性。           
  使用自旋锁的时候，如果发生多线程竞争锁的情况，加锁失败的线程会进入 **“忙等待”** 状态，一直自旋，利用 CPU 周期，直到锁可用。忙等待可以通过 while 循环实现，但是用 CPU 级别的 PAUSE 指令更加节能。          
  自旋锁的系统开销较小，在多核系统中一般不主动产生线程上下文切换。但如果被锁住的代码执行时间较长，自旋状态的线程也会长时间占用 CPU 资源。与互斥锁正相反，**自旋锁适用于代码执行时间较短的场景。**         
  特别的，在单核单线程系统中，自旋锁是不适用的，即使代码里实现了自旋锁，其也会被编译器优化掉。这是因为当一个线程进入自旋状态，证明其正在等待某一资源。在单核单线程 CPU 系统中，一旦发生了这种自旋锁，那么当前持有资源的线程也会由于无法获得 CPU 而一直等待。这样，占用 CPU 的线程等待另一个线程释放资源，占用资源的线程等待另一个线程释放 CPU ，从而导致程序进入死锁。          
  

* **读写锁：**               
  互斥锁和共享锁是两种最基本的加锁方式，更高级的锁会选择其中一个进行升级，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。读写锁从字面意思我们也可以知道，它由 *读锁* 和 *写锁* 两部分构成，如果只读取共享资源用 *读锁* 加锁，如果要修改共享资源则用 *写锁* 加锁。             
  所以，**读写锁适用于能明确区分读操作和写操作的场景**。              
  读写锁的工作原理是：              
  * 当 *写锁* 没有被线程持有，多个线程可以并发地持有 *读锁* ，这大大提高了共享资源的访问效率。     
  * 当 *写锁* 被线程持有，读线程获取 *读锁* 的操作会被阻塞，其他线程获取 *写锁* 的操作也会被阻塞。     
  
  从而得出，*写锁* 是独占锁，任何时候只能被一个线程持有，可以有互斥锁或自旋锁等实现；而 *读锁* 是共享锁，可以同时被多个线程持有。           
  显然，读写锁在**读多写少的场景下更能发挥出优势**。          

  根据优先级的不同，读写锁可以实现为 *读优先锁* 和 *写优先锁* 。          
  读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。             
  写优先锁希望优先服务写线程，其工作方式是，当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取写锁。            

  读优先锁对于读线程的并发性更好，但如果一直有读线程获取读锁，那么写线程永远无法获取写锁，就产生了写线程饥饿的现象。同理，写优先锁情况下，如果一直有写线程获取写锁，读线程也会产生饥饿现象。对于线程饥饿问题的一种解决方式是“读写公平锁”：              
  读写公平锁的一种简单实现是，维护一个队列，所有获取锁的线程按顺序入队列，不管是读线程还是写线程，按照先进先出的原则出队列加锁即可。这样读线程仍然可以并发，也不会出现饥饿现象。          
 

## Debug 和 Release                
Debug 版本和 Release 版本其实就是 C/C++ 编译器优化级别的不同。gcc/g++ 编译器的有如下几种优化级别：              
* O0： 默认级别，不开启优化项，方便调试，也就是 BEBUG 模式。           
* Og： 开启部分不影响调试信息的优化项。        
* O1： 较保守的优化。         
* O2： 常见的 Release 级别，打开几乎全部优化项。           
* Os： 比 O2 更保守一些。           
* O3： 更加激进。             
* Ofast： 不严格遵循标准，在 O3 的基础上开启一些可能导致不符合 IEEE 浮点数标准的优化项。      

DEBUG 是调试版本，编译的结果通常包含调试信息，不进行任何优化，因此代码运行相对较慢。RELEASE 是发布版本，不携带调试信息，比如断点，同时编译器对代码进行很多优化，是代码更小，速度更快。RELEASE 因此也比 DEBUG 需要更长的编译时间。               
DEBUG 模式下，申请内存时会多分配一些内存空间，分布在申请内存块的前后，用于存放调试信息；RELEASE 则不会。对于未初始化变量，DEBUG 默认将其初始化，RELEASE 则不会。DEBUG 下可以使用断言，RELEASE 则会直接无视掉断言语句。 DEBUG 以 32 字节为单位分配内存，例如当申请 24 字节内存时，RELEASE 是正常的 24 字节，而 DEBUG 则会多申请 8 个字节；所以有些数组越界问题在 DEBUG 模式下可以安全运行，RELEASE 模式下则会出现问题。DEBUG 模式下记录了可以正常使用 gdb 去 debug，但是 RELEASE 可能会将用于记录程序运行信息的符号表 优化掉，导致无法直接 gdb。如果需要在 release 版本 gdb 的话，可以使用 objcopy 生成一个 debug 信息，在 gdb 的时候，先加载符号信息 `file xxx.debug`，然后再进行调试。         


#### Core Dump 是怎么产生的          
上文提到了 core dump 。当程序运行的过程中异常终止或崩溃，操作系统会将程序当时的内存状态记录下来，保存在一个文件中，这种行为就叫做Core Dump。 使用命令 `gdb program core` 来查看 core 文件，其中 program 为可执行程序名，core 为生成的 core 文件名。             


## DMA 和零拷贝            
网络编程中，服务端面临客户端请求时，会发生如下系统调用：        
```c++
// 伪代码              
File::read(file, buf, len);
Socket::send(socket, bufm len);
```
也即将数据从外部存储设备读入用户空间，然后通过外部发送设备（网卡）发送出去。在没有使用任何优化技术的情况下，这一过程需要进行四次数据拷贝，进行四次上下文切换，如下图所示：           
<div align=center><img src="https://raw.githubusercontent.com/OUCliuxiang/OUCliuxiang.github.io/master/img/CSbasis/OS01.jpg"></div>         

其中，四次拷贝：             
* 物理设备 <--> 内存：             
  * CPU 负责将数据从硬盘拷贝到内核空间的 Page Cache 中。            
  * CPU 负责将数据从内核空间的 Socket 缓冲区拷贝到网络设备中。            
* 内存内部拷贝：             
  * CPU 负责将数据从内核空间的 Page Cache 拷贝到用户控件缓冲区。             
  * CPU 负责将数据从用户空间缓冲区拷贝到内核空间 Socket 缓冲区。       

线程的四次上下文切换：             
1. read 系统调用时，从用户态切换到内核态。            
2. read 系统调用完毕，从内核态切换回用户态。             
3. write 系统调用时，从用户态陷入到内核态。              
4. write 系统调用完毕，从内核态恢复到用户态。            

CPU 直接控制硬盘数据 IO 需要 CPU 不断轮询当前字节数据 IO 是否完成，但由于 CPU 处理速度较高，而设备间 IO 速度较慢，这种方式往往导致 CPU 大多数时间处于忙等待状态，效率较低。上下文切换的成本也不小：一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。               
现代计算机通过 DMA (Direct Memory Access，直接内存访问) 机制实现设备间 IO，也即通过主板上的 DMAC (DMA Controller，DMA 控制器) 控制数据 IO。DMAC 作为一个协控制器接管线程负责设备间 IO，在此期间 CPU 资源被释放，并在 IO 完成后，通知 CPU 重新接管线程。但是**设备内部的数据拷贝还需要 CPU 来亲力亲为**。如下图：               
<div align=center><img src="https://raw.githubusercontent.com/OUCliuxiang/OUCliuxiang.github.io/master/img/CSbasis/OS02.png"></div>         


#### 关于 Page Cache             
上文提到了页缓存 Page Cache，作简要介绍。          

由于读写硬盘的速度远远慢于读写内存的速度，所以为了避免每次读写文件时都对硬盘进行读写操作，Linux 内核使用 Page Cache （页缓存） 机制对文件中的数据进行缓存。Linux 内核会以页大小（4KB）为单位，将文件划分为多数据块。当用户对文件中的某个数据块进行读写操作时，内核首先会申请一个内存页（页缓存）与文件中的数据块进行绑定。用户读写数据实际是对文件的 `页缓存` 进行读写：            
* 当从文件中读取数据时，如果要读取的数据所在的页缓存已经存在，那么就直接把页缓存的数据拷贝给用户即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把页缓存的数据拷贝给用户。              
* 当向文件中写入数据时，如果要写入的数据所在的页缓存已经存在，那么直接把新数据写入到页缓存即可。否则，内核首先会申请一个空闲的内存页（页缓存），然后从文件中读取数据到页缓存，并且把新数据写入到页缓存中。对于被修改的页缓存，内核会周期性地把这些页缓存刷新到文件中。              

当物理内存空间紧张时，内核需要把已经缓存着的内容选择一部分清除。选择的策略通常是基于最近最少使用（LRU）而改进的 LRU/n 算法，也即维护 n 个最近最少使用链表，将最近被访问的页缓存插入链表尾，而链表头存储的就是最近最少使用的页缓存，可以被回收。           


